**[ ] Task 2: Полноценная обработка аномальных данных (п. 2 ТЗ)**

* Цель: Выделять записи с некорректными/отсутствующими координатами в отдельные `ANO_*.xlsx` и `ANO_*.kml` файлы с указанием причины.
* Файлы: `separate_into_files.py`, `xlsx_to_kml.py`

  * **[ ] 2.1.** Идентификация аномалий:
    * **[ ] 2.1.1.** В `xlsx_to_kml.py::parse_coordinates`:
      * Если парсинг не удался (нет координат, неверный формат), функция должна возвращать не пустой список, а специальный маркер ошибки или `None`.
      * Если координаты выходят за допустимый диапазон (см. Task 3), также вернуть маркер ошибки/`None`.
      * Логировать причину невозможности парсинга/невалидности.
    * **[ ] 2.1.2.** В `separate_into_files.py::process_file` (или новой функции):
      * Перед вызовом KML-генерации для региона, пройти по строкам DataFrame этого региона.
      * Проверить столбец "Место водопользования": если он пустой или не содержит ожидаемых маркеров координат (например, `°`, `"`, `м.`), пометить строку как аномальную ("Отсутствуют координаты").
      * Для строк с потенциальными координатами вызвать `parse_coordinates`. Если вернулся маркер ошибки/`None`, пометить строку как аномальную ("Некорректный формат/диапазон координат").
  * **[ ] 2.2.** Разделение данных:
    * **[ ] 2.2.1.** Модифицировать `separate_into_files.py::process_file`:
      * При обработке каждого региона создавать два временных DataFrame: `valid_df` и `anomalous_df`.
      * На основе проверок из п. 2.1 распределять строки исходного DataFrame региона по этим двум.
      * В `anomalous_df` добавить новую колонку "Причина аномалии" и заполнить её на основе результата проверки (п. 2.1.2).
  * **[ ] 2.3.** Сохранение `ANO_*.xlsx`:
    * **[ ] 2.3.1.** Создать функцию `save_anomalous_xlsx(region_name, anomalous_df, header_rows, column_widths)`.
    * Эта функция должна:
      * Принимать имя региона и DataFrame с аномальными данными (включая колонку "Причина аномалии").
      * Добавлять стандартные строки заголовка (`header_rows`) к `anomalous_df`.
      * Формировать имя файла: `ANO_[Название_округа].xlsx` (например, `ANO_Амурская_область.xlsx`).
      * Сохранять DataFrame в этот файл в директории `output/separated_regions/` (или создать поддиректорию `anomalous`).
      * Применять форматирование (ширина столбцов, объединение ячеек), используя `apply_formatting`.
    * **[ ] 2.3.2.** Вызывать эту функцию из `process_file` для каждого региона, если `anomalous_df` не пуст.
  * **[ ] 2.4.** Создание `ANO_*.kml`:
    * **[ ] 2.4.1.** Определить содержимое `ANO_*.kml`. ТЗ неясно. Возможные варианты:
      * **Вариант А (Рекомендуемый):** Файл содержит только папки/описания без геометрии, перечисляя аномальные записи и причины.
      * **Вариант Б:** Создать placeholder-точку (например, в 0,0 или центре региона) для каждой аномальной записи с её описанием.
    * **[ ] 2.4.2.** Создать функцию `create_anomalous_kml(region_name, anomalous_df)`.
    * Эта функция должна:
      * Принимать имя региона и DataFrame аномальных данных.
      * Формировать имя файла `ANO_[Название_округа].kml`.
      * Создавать KML структуру согласно выбранному варианту (А или Б). В описании указывать данные объекта и причину аномалии.
      * Сохранять KML в `output/separated_regions/kml/` (или отдельную папку).
    * **[ ] 2.4.3.** Вызывать эту функцию из `process_file` для каждого региона, если `anomalous_df` не пуст.
  * **[ ] 2.5.** Рефакторинг:
    * Удалить или полностью переписать функцию `save_objects_without_coordinates` в `separate_into_files.py`, так как её логика заменяется новой системой обработки аномалий.

---

**[ ] Task 3: Проверка корректности координат (п. 3 ТЗ)**

* Цель: Добавить проверку диапазонов широты (-90..90) и долготы (-180..180).
* Файл: `xlsx_to_kml.py`
* Функция: `parse_coordinates`

  * **[ ] 3.1.** Добавить проверку после конвертации в десятичные градусы:
    * Внутри цикла, где вычисляются `lat` и `lon` из ДМС или МСК.
    * Добавить условие: `if not (-90 <= lat <= 90 and -180 <= lon <= 180):`
  * **[ ] 3.2.** Обработка ошибки диапазона:
    * Если проверка не пройдена:
      * Залогировать ошибку с указанием строки и неверных значений (`self.logger.warning(...)`).
      * Пропустить добавление этой точки в `result` (или вернуть маркер ошибки, см. Task 2.1.1).

---

**[ ] Task 4: Корректное содержимое меток KML (п. 4 ТЗ)**

* Цель: Включить в описание KML-метки поля: наименование водопользователя, цель водопользования, дата прекращения действия договора.
* Файл: `xlsx_to_kml.py`
* Функция: `create_kml_from_coordinates`

  * **[ ] 4.1.** Найти индексы недостающих колонок:
    * В `get_column_indices` добавить поиск индексов для колонок "Водопользователь" (убедиться, что это не то же самое, что "Наименование" или "Владелец" в вашем коде) и "Дата прекращения действия договора".
  * **[ ] 4.2.** Обновить формирование описания (`description`):
    * Модифицировать цикл, создающий список `desc`.
    * Добавить строки для "Водопользователь" и "Дата прекращения действия договора", используя найденные индексы.
    * Убрать из описания поля, *не требуемые* ТЗ, если они не несут важного контекста (например, "Уполномоченный орган", "Вид водопользования", "Владелец" - если он дублирует Водопользователя). Поле "Цель водопользования" уже есть и требуется.
  * **[ ] 4.3.** Тестирование: Убедиться, что в выходных KML-файлах описание точек/линий/полигонов соответствует ТЗ.

---

**[ ] Task 5: Именование KML в режиме "Single Convert" (п. 5 ТЗ)**

* Цель: Сделать именование KML в режиме "Single Convert" более консистентным (по возможности, на основе региона).
* Файл: `main.py`
* Функция: `main` (блок `if user_input == "1":`)

  * **[ ] 5.1.** (Опционально, требует прояснения ТЗ) Попытаться извлечь имя региона:
    * После загрузки `workbook = load_workbook(...)`, проанализировать первую значащую строку в колонке "Место водопользования" (или первой колонке, если Task 1 еще не сделан) для определения основного региона в файле.
    * Если регион найден, использовать его для имени KML файла: `output_kml_name = f"{extracted_region}.kml"`.
    * Если регион определить не удалось или файл содержит много регионов, оставить текущую логику: `output_kml_name = file_name.rsplit(".", 1)[0] + ".kml"`.
  * **[ ] 5.2.** Использовать `output_kml_name` при вызове `create_kml_from_coordinates`.

---

**[ ] Task 6: Корректное логирование ошибок (п. 6 ТЗ)**

* Цель: Писать логи ошибок в файл `errors.log`.
* Файл: `utils.py`
* Функция: `setup_logging`

  * **[ ] 6.1.** Изменить имя файла лога:
    * Заменить `log_file = logs_dir / f"separate_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"` на `log_file = logs_dir / "errors.log"`.
  * **[ ] 6.2.** (Опционально) Настроить уровень логирования:
    * Если в `errors.log` должны попадать *только* ошибки, изменить `level=logging.INFO` на `level=logging.WARNING` или `level=logging.ERROR`.
    * Если допустимо писать все уровни, оставить `level=logging.INFO`, но убедиться, что реальные ошибки логируются через `logger.error()` или `logger.exception()`.
  * **[ ] 6.3.** Проверить код: Убедиться, что все ожидаемые ошибки (ошибки парсинга, диапазонов, файловые операции и т.д.) действительно логируются с уровнем ERROR или WARNING.

---

**[ ] Task 7: Производительность и поддержка больших файлов (п. 7 ТЗ)**

* Цель: Обеспечить обработку 10 000 строк за время <= 5 минут.
* Файлы: Все основные модули (`main.py`, `separate_into_files.py`, `xlsx_to_kml.py`).

  * **[ ] 7.1.** Подготовка тестовых данных:
    * Создать Excel-файл с ~10 000 - 15 000 строк реальных или сгенерированных данных, имитирующих структуру исходного файла.
  * **[ ] 7.2.** Профилирование:
    * Запустить полный цикл обработки (разделение + генерация KML) на тестовом файле.
    * Измерить общее время выполнения.
    * Использовать `cProfile` или другие инструменты для определения самых медленных участков кода (например, чтение Excel, парсинг строк, запись KML).
  * **[ ] 7.3.** Анализ узких мест:
    * Определить, какие операции занимают больше всего времени.
  * **[ ] 7.4.** Оптимизация (если время > 5 минут):
    * **Чтение Excel:** Если чтение медленное, попробовать `pandas.read_excel` с параметром `engine='openpyxl'` (уже используется неявно) или исследовать `engine='calamine'` (если доступен). Рассмотреть чтение по частям (`chunksize`), если обработка всего файла в памяти является проблемой.
    * **Обработка DataFrame:** Использовать векторизованные операции pandas там, где это возможно, вместо итерации по строкам (`iterrows`).
    * **Парсинг координат:** Оптимизировать регулярные выражения или логику парсинга, если она медленная.
    * **Запись KML/Excel:** Если запись медленная, проверить, нет ли избыточных операций.
  * **[ ] 7.5.** Повторное тестирование: После оптимизаций снова измерить время выполнения.

---

**[ ] Завершающий этап:**

* **[ ] 8.1.** Финальное тестирование: Прогнать весь функционал на различных наборах данных (маленьких, больших, с аномалиями, без них).
* **[ ] 8.2.** Ревью кода: Провести ревью внесенных изменений.
* **[ ] 8.3.** Обновление документации: Отразить изменения в `README.md` или `DOCS.md`.
